{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d25721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(token = token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926ba116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer ...\n",
      "Using device: cuda\n",
      "Loading model ...\n",
      "Tokenizer and model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer ...\")\n",
    "\n",
    "model_1b = 'meta-llama/Llama-3.2-1B'\n",
    "model_8b = 'meta-llama/Meta-Llama-3-8B'\n",
    "\n",
    "\n",
    "current_model = model_1b\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(current_model)\n",
    "print(\"Loading model ...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   current_model,\n",
    "   torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "   device_map=\"auto\",\n",
    "   # load_in_4bit=True, \n",
    "   )\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Required\n",
    "print(\"Tokenizer and model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b445450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"qiaojin/PubMedQA\",'pqa_artificial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20329574",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be19d982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n",
       "    num_rows: 211269\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2df0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_data = dataset.select(range(1000))\n",
    "mini_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acc1f03c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmini_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "mini_data.to(\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfce0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronic rhinosinusitis (CRS) is a heterogeneous disease with an uncertain pathogenesis. Group 2 innate lymphoid cells (ILC2s) represent a recently discovered cell population which has been implicated in driving Th2 inflammation in CRS; however, their relationship with clinical disease characteristics has yet to be investigated.\n",
      "The aim of this study was to identify ILC2s in sinus mucosa in patients with CRS and controls and compare ILC2s across characteristics of disease.\n",
      "A cross-sectional study of patients with CRS undergoing endoscopic sinus surgery was conducted. Sinus mucosal biopsies were obtained during surgery and control tissue from patients undergoing pituitary tumour resection through transphenoidal approach. ILC2s were identified as CD45(+) Lin(-) CD127(+) CD4(-) CD8(-) CRTH2(CD294)(+) CD161(+) cells in single cell suspensions through flow cytometry. ILC2 frequencies, measured as a percentage of CD45(+) cells, were compared across CRS phenotype, endotype, inflammatory CRS subtype and other disease characteristics including blood eosinophils, serum IgE, asthma status and nasal symptom score.\n",
      "35 patients (40% female, age 48 Â± 17 years) including 13 with eosinophilic CRS (eCRS), 13 with non-eCRS and 9 controls were recruited. ILC2 frequencies were associated with the presence of nasal polyps (P = 0.002) as well as high tissue eosinophilia (P = 0.004) and eosinophil-dominant CRS (P = 0.001) (Mann-Whitney U). They were also associated with increased blood eosinophilia (P = 0.005). There were no significant associations found between ILC2s and serum total IgE and allergic disease. In the CRS with nasal polyps (CRSwNP) population, ILC2s were increased in patients with co-existing asthma (P = 0.03). ILC2s were also correlated with worsening nasal symptom score in CRS (P = 0.04).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(mini_data[0]['context']['contexts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90630e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eba113fae543a1b53cddd8969fdc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_train(example):\n",
    "    context_text = \"\\n\".join(example['context']['contexts'])\n",
    "\n",
    "    prompt = (\n",
    "        f\"Contexts:\\n{context_text}\\n\\n\"\n",
    "        \"Based on the contexts above, answer the question below with 'Yes', 'No', or 'Maybe'.\\n\"\n",
    "        \"Then, provide a short explanation that justifies your answer using evidence from the context.\\n\"\n",
    "        f\"Question: {example['question']}\\n\"\n",
    "        f\"Answer: {example['final_decision']}\\n\"\n",
    "        f\"Explanation: {example['long_answer']}\\n\"\n",
    "        )\n",
    "    \n",
    "    tokenized =  tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",         # optional, but safer with Trainer\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    # tokenized[\"labels\"] = [\n",
    "    #     token if token != tokenizer.pad_token_id else -100\n",
    "    #     for token in tokenized[\"labels\"]\n",
    "    # ]\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenized_dataset = mini_data.map(tokenize_train)\n",
    "\n",
    "# remove the columns that are not needed\n",
    "# tokenized_dataset = tokenized_dataset.remove_columns(\n",
    "#     [\n",
    "#         'pubid',\n",
    "#         'question',\n",
    "#         'final_decision',\n",
    "#         'long_answer',\n",
    "#         'context'\n",
    "#     ]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2719caa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pubid', 'question', 'context', 'long_answer', 'final_decision', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2f773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                         # Rank of LoRA updates\n",
    "    lora_alpha=16,               # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Inject into attention blocks\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2342ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc143fb7d72a4efbab247dec786179d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[43mtokenized_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlength\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(lengths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:3079\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3075\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3076\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3077\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3078\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3079\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3080\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3081\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:3501\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[0m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[1;32m   3500\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3501\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m iter_outputs(shard_iterable):\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3503\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:3475\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3474\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3475\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:3398\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3396\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3397\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[0;32m-> 3398\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lengths \u001b[38;5;241m=\u001b[39m tokenized_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)})\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(lengths[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/formatting/formatting.py:280\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[0;32m--> 280\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format\u001b[38;5;241m.\u001b[39mremove(key)\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/formatting/formatting.py:375\u001b[0m, in \u001b[0;36mLazyRow.format\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/formatting/formatting.py:459\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_column(column, pa_table\u001b[38;5;241m.\u001b[39mcolumn_names[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/datasets/formatting/formatting.py:146\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lengths = tokenized_dataset.map(lambda x: {\"length\": len(x[\"input_ids\"])})\n",
    "print(max(lengths[\"length\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1524d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdd765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:PJRT is now the default runtime. For more information, see https://github.com/pytorch/xla/blob/master/docs/pjrt.md\n",
      "WARNING:root:Found CUDA without GPU_NUM_DEVICES. Defaulting to PJRT_DEVICE=CUDA with GPU_NUM_DEVICES=1\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746863147.217869   61406 service.cc:146] XLA service 0x5651d17a3660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "/var/tmp/ipykernel_61406/2289559833.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "I0000 00:00:1746863147.219673   61406 service.cc:154]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "I0000 00:00:1746863147.224489   61406 se_gpu_pjrt_client.cc:897] Using BFC allocator.\n",
      "I0000 00:00:1746863147.224597   61406 gpu_helpers.cc:114] XLA backend allocating 17677664256 bytes on device 0 for BFCAllocator.\n",
      "I0000 00:00:1746863147.225184   61406 gpu_helpers.cc:154] XLA backend will use up to 5892554752 bytes on device 0 for CollectiveBFCAllocator.\n",
      "/opt/python/3.10/lib/python3.10/site-packages/torch_xla/amp/grad_scaler.py:36: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "I0000 00:00:1746863149.976732   61406 cuda_dnn.cc:530] Loaded cuDNN version 90100\n",
      "2025-05-10 07:46:13.295985: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:14.170330: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:14.696598: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:15.095906: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00GiB (1077936144 bytes), down from 1.00GiB (1077936144 bytes) originally\n",
      "2025-05-10 07:46:15.135480: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:15.184964: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:15.195513: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:15.784170: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:15.912913: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:16.239456: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:16.596980: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:16.803741: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:17.101981: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:17.521145: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:17.622216: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:18.214048: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.008122: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.364025: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.368635: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.479107: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.560581: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:19.976959: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.030371: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.031199: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.464361: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:20.642944: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.802496: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.825927: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:20.907955: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:21.912292: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:21.915897: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:22.560565: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:22.631688: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:22.668398: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:22.886176: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:22.955226: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:23.028383: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:23.142643: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:23.556450: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:23.771237: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:23.899372: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:23.955739: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:24.042847: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:24.059485: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:24.305695: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:24.437384: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:24.503185: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:24.667395: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:25.131215: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:25.493515: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:25.497747: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:25.615863: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:25.862634: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:25.931853: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:26.240614: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:26.329928: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:26.545724: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.82GiB (34162606096 bytes), down from 31.82GiB (34162606096 bytes) originally\n",
      "2025-05-10 07:46:26.590490: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:26.832570: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.062326: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:27.150064: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:27.154914: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:27.492052: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.495847: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:27.566061: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:27.607145: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:27.714287: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.718013: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.722809: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.754372: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.758026: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:27.963023: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:28.054788: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:28.141749: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:28.145390: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:28.300328: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:28.947162: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:29.003043: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:29.009943: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1100052693008 bytes), down from 1.00TiB (1100052693008 bytes) originally\n",
      "2025-05-10 07:46:29.055487: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:29.261258: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:29.360681: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:29.696059: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:29.779570: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:29.803195: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:29.807572: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:29.877866: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:29.960352: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:30.604023: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:30.814504: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:30.814554: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:30.872251: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:31.130100: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:31.193912: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:31.451110: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:31.551865: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:31.784852: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -14.00GiB (-15036198379 bytes) by rematerialization; only reduced to 31.31GiB (33621540864 bytes), down from 31.31GiB (33621540864 bytes) originally\n",
      "2025-05-10 07:46:31.789159: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:31.888271: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:31.954026: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:31.961322: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:32.031296: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:32.336855: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:32.654448: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:32.966793: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:32.970131: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:33.102833: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:33.112669: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:33.331880: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:33.336435: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:33.344425: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:33.422194: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:33.762884: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:33.858157: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.072666: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.132458: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:34.144235: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.147856: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.423313: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.742870: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:34.937467: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00GiB (1077936144 bytes), down from 1.00GiB (1077936144 bytes) originally\n",
      "2025-05-10 07:46:34.988250: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.082598: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.314431: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.403374: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.440614: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.573109: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:35.676389: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:35.897746: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 1.00TiB (1099511627776 bytes), down from 1.00TiB (1099511627776 bytes) originally\n",
      "2025-05-10 07:46:35.909232: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 1.00TiB (1100052693008 bytes), down from 1.00TiB (1100052693008 bytes) originally\n",
      "2025-05-10 07:46:36.027004: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:36.376261: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:36.487333: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:36.768758: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.126355: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.165120: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.479496: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.491725: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.495893: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.555662: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.660174: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:37.895861: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.323519: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.378895: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.379741: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.522055: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.775350: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.959468: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:38.970486: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.069501: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.112123: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.384557: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.797687: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.862794: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:39.889951: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.179784: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.314090: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.823478: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.864554: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.931803: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:40.975638: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:41.555397: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:41.660740: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:41.717691: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:42.031153: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:42.379516: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734674 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:42.799534: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:43.079176: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:43.255934: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 1.00TiB (1100052693008 bytes), down from 1.00TiB (1100052693008 bytes) originally\n",
      "2025-05-10 07:46:43.287265: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:43.293656: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:43.398317: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:43.820680: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:44.053372: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:44.100597: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:44.120920: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:44.190251: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:44.221697: W external/xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below -957.07GiB (-1027642734676 bytes) by rematerialization; only reduced to 512.00MiB (536870912 bytes), down from 512.00MiB (536870912 bytes) originally\n",
      "2025-05-10 07:46:47.486506: W external/tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.00TiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Bad StatusOr access: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1099528404992 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./lora-llama3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     19\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,\n\u001b[1;32m     20\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/transformers/trainer.py:2611\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2607\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2611\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/accelerate/optimizer.py:165\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 454\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/torch_xla/amp/grad_scaler.py:77\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m   retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m   \u001b[43mxm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmark_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\n\u001b[1;32m     79\u001b[0m       v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m     80\u001b[0m     retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/python/3.10/lib/python3.10/site-packages/torch_xla/core/xla_model.py:1055\u001b[0m, in \u001b[0;36mmark_step\u001b[0;34m(wait, reset_scope)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xu\u001b[38;5;241m.\u001b[39mgetenv_as(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXLA_EMIT_STEPLOG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1050\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m   1051\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch_xla.core.xla_model::mark_step\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1052\u001b[0m       end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1053\u001b[0m       file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1054\u001b[0m       flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1055\u001b[0m \u001b[43mtorch_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_XLAC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla_step_marker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_XLAC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla_get_default_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv_as\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXLA_SYNC_WAIT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_scope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# Only emit metrics from the first local device index, to avoid emitting the\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# same values from different threads.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_master_ordinal():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Bad StatusOr access: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1099528404992 bytes."
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-llama3-8B\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc52ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.554432"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33554432/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ef19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.074154496 GB allocated\n",
      "16.076767232 GB reserved\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated() / 1e9, \"GB allocated\")\n",
    "print(torch.cuda.memory_reserved() / 1e9, \"GB reserved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5911526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
